{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3cf31af16cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class EarlyStopper:  # We define this class so that it performs the EarlyStopping check at each epoch\n",
    "    def __init__(self, patience=1, min_delta=0, save_path=\"./best_model_with_label.pt\"):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.save_path = save_path\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss, model):\n",
    "        \"\"\"Returns whether the training should stop or not. If stopping criterion is not met returns False.\"\"\"\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "def plot_history(history: dict, plot_list=[], scale=\"linear\"):\n",
    "    fig = plt.figure(figsize=(14, 7))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    for plot in plot_list:\n",
    "        plt.plot(history[\"epoch\"], history[plot], label=plot)\n",
    "    plt.yscale(scale)\n",
    "    plt.legend(fontsize=30)\n",
    "    plt.show()\n",
    "def calculate_iou(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcula el IoU entre las predicciones y las etiquetas reales.\n",
    "    \n",
    "    Args:\n",
    "        y_true (torch.Tensor): Tensor de etiquetas reales.\n",
    "        y_pred (torch.Tensor): Tensor de predicciones del modelo.\n",
    "        threshold (float): Umbral para binarizar las predicciones.\n",
    "        \n",
    "    Returns:\n",
    "        float: Valor promedio de IoU.\n",
    "    \"\"\"\n",
    "    y_pred = (y_pred > threshold).float()  # Binarizar predicciones\n",
    "    intersection = (y_true * y_pred).sum(dim=(1, 2, 3))\n",
    "    union = y_true.sum(dim=(1, 2, 3)) + y_pred.sum(dim=(1, 2, 3)) - intersection\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)  # Evitar división por 0\n",
    "    return iou.mean().item()\n",
    "def calculate_dice(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcula el coeficiente de Dice entre las predicciones y las etiquetas reales.\n",
    "    \n",
    "    Args:\n",
    "        y_true (torch.Tensor): Tensor de etiquetas reales.\n",
    "        y_pred (torch.Tensor): Tensor de predicciones del modelo.\n",
    "        threshold (float): Umbral para binarizar las predicciones.\n",
    "        \n",
    "    Returns:\n",
    "        float: Valor promedio de Dice.\n",
    "    \"\"\"\n",
    "    y_pred = (y_pred > threshold).float()  # Binarizar predicciones\n",
    "    intersection = (y_true * y_pred).sum(dim=(1, 2, 3))\n",
    "    dice = (2 * intersection + 1e-6) / (y_true.sum(dim=(1, 2, 3)) + y_pred.sum(dim=(1, 2, 3)) + 1e-6)\n",
    "    return dice.mean().item()\n",
    "def train_model(model,\n",
    "                train_dataloader=None,\n",
    "                val_dataloader=None,\n",
    "                criterion=None,\n",
    "                lr=None,\n",
    "                optimizer=None,\n",
    "                epochs=None,\n",
    "                early_stopper=None):\n",
    "    history = {\"loss\": [], \"val_loss\": [], \"epoch\": [], \"avg_iou\": [], \"avg_dice\": []}\n",
    "    optimizer = optimizer(model.parameters(), lr=lr)\n",
    "    scaler = GradScaler('cuda')  # Inicializar el escalador de gradientes\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, targets = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Usar autocast para operaciones de precisión mixta\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            # Escalar la pérdida y retropropagar\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Escalar el optimizador para actualizar los parámetros\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_dataloader)\n",
    "        history[\"loss\"].append(avg_loss)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        running_vloss = 0.0\n",
    "        iou_scores = []\n",
    "        dice_scores = []\n",
    "        with torch.no_grad():\n",
    "            for vdata in val_dataloader:\n",
    "                vinputs, vtargets = vdata[0].to(DEVICE), vdata[1].to(DEVICE)\n",
    "\n",
    "                with autocast('cuda'):\n",
    "                    voutputs = model(vinputs)\n",
    "                    vloss = criterion(voutputs, vtargets)\n",
    "\n",
    "                running_vloss += vloss.item()\n",
    "\n",
    "                # Calcular IoU y Dice\n",
    "                iou = calculate_iou(vtargets, torch.sigmoid(voutputs))\n",
    "                dice = calculate_dice(vtargets, torch.sigmoid(voutputs))\n",
    "                iou_scores.append(iou)\n",
    "                dice_scores.append(dice)\n",
    "\n",
    "        avg_vloss = running_vloss / len(val_dataloader)\n",
    "        avg_iou = sum(iou_scores) / len(iou_scores)\n",
    "        avg_dice = sum(dice_scores) / len(dice_scores)\n",
    "\n",
    "        history[\"val_loss\"].append(avg_vloss)  # Store current val_loss value\n",
    "        history[\"epoch\"].append(epoch + 1)  # Store current epoch\n",
    "        history[\"avg_iou\"].append(avg_iou)\n",
    "        history[\"avg_dice\"].append(avg_dice)\n",
    "        # Early stopping\n",
    "        if early_stopper.early_stop(avg_vloss, model):\n",
    "            break\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}: IoU = {avg_iou:.4f}, Dice = {avg_dice:.4f}\" + 'LOSS train {} valid {}'.format(avg_loss,\n",
    "                                                                                                               avg_vloss))\n",
    "\n",
    "    # Cargar el mejor modelo\n",
    "    model.load_state_dict(torch.load(early_stopper.save_path, weights_only=True))\n",
    "\n",
    "    return history\n",
    "\n",
    "def load_dataset(root_dir):\n",
    "    \"\"\"\n",
    "    Carga todas las imágenes y etiquetas desde una carpeta raíz con múltiples subcarpetas.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Ruta de la carpeta raíz que contiene las carpetas kosXX.\n",
    "\n",
    "    Returns:\n",
    "        images (list): Lista de arrays de imágenes.\n",
    "        labels (list): Lista de arrays de mapas de defectos.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    images_augmented = []\n",
    "    labels_augmented = []\n",
    "    # Iterar por cada carpeta (e.g., kos01, kos02, ...)\n",
    "    for folder in sorted(os.listdir(root_dir)):\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "\n",
    "        if os.path.isdir(folder_path):  # Asegurarse de que sea una carpeta\n",
    "            # Iterar por cada archivo en la carpeta\n",
    "            for file in sorted(os.listdir(folder_path)):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "\n",
    "                # Cargar imágenes y etiquetas\n",
    "                if file.endswith(\".jpg\"):  # Es una imagen\n",
    "                    if file.endswith((\"aug_0.jpg\", \"aug_1.jpg\", \"aug_2.jpg\", \"aug_3.jpg\", \"aug_4.jpg\", \"aug_5.jpg\",\n",
    "                                      \"aug_6.jpg\")):\n",
    "                        img = Image.open(file_path).convert(\"L\")  # Convertir a escala de grises\n",
    "                        images_augmented.append(np.array(img))  # Convertir a array NumPy\n",
    "                    else:\n",
    "                        img = Image.open(file_path).convert(\"L\")  # Convertir a escala de grises\n",
    "                        images.append(np.array(img))  # Convertir a array NumPy\n",
    "                elif file.endswith(\".bmp\"):  # Es un mapa de etiquetas\n",
    "                    if file.endswith((\"aug_0_label.bmp\", \"aug_1_label.bmp\", \"aug_2_label.bmp\", \"aug_3_label.bmp\",\n",
    "                                      \"aug_4_label.bmp\", \"aug_5_label.bmp\", \"aug_6_label.bmp\")):\n",
    "                        label = Image.open(file_path).convert(\"L\")  # Convertir a escala de grises\n",
    "                        labels_augmented.append(np.array(label))\n",
    "                    else:\n",
    "                        label = Image.open(file_path).convert(\"L\")  # Convertir a escala de grises\n",
    "                        labels.append(np.array(label))  # Convertir a array NumPy\n",
    "\n",
    "    return images, labels, images_augmented, labels_augmented"
   ],
   "id": "7e7723d9e3ef7da1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ruta de la carpeta raíz\n",
    "root_dir = r\"C:\\Users\\jerij\\Carpetas\\Clases Formaciones Curro\\Master\\2Semestre\\Proyecto\\Data\\Imagenes_defectos\"\n",
    "images, labels, images_augmented, labels_augmented = load_dataset(root_dir)\n",
    "\n",
    "# Imprimir información del dataset\n",
    "print(f\"Número de imágenes cargadas: {len(images)}\")\n",
    "print(f\"Número de etiquetas cargadas: {len(labels)}\")\n",
    "print(f\"Número de imágenes augmented cargadas: {len(images_augmented)}\")\n",
    "print(f\"Número de etiquetas augmented cargadas: {len(labels_augmented)}\")\n",
    "images = [img / 255.0 for img in images]\n",
    "labels = [label / 255.0 for label in labels]\n",
    "images_augmented = [img / 255.0 for img in images_augmented]\n",
    "labels_augmented = [label / 255.0 for label in labels_augmented]\n",
    "# Dividir en entrenamiento y prueba\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Dividir prueba en validación y conjunto final de prueba\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(\n",
    "    test_images, test_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "# Agregar datos aumentados solo al conjunto de entrenamiento\n",
    "train_images += images_augmented\n",
    "train_labels += labels_augmented\n",
    "from torchvision import transforms\n",
    "\n",
    "# Transformaciones para las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((1024, 512)),\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "])\n",
    "\n",
    "# Transformaciones para las etiquetas\n",
    "label_transform = transforms.Compose([\n",
    "    transforms.Resize((1024, 512)),\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "])"
   ],
   "id": "23d1fbf50469fd0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None, label_transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.label_transform = label_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convertir las imágenes y etiquetas de NumPy a PIL\n",
    "        image = Image.fromarray(self.images[idx])\n",
    "        label = Image.fromarray(self.labels[idx])\n",
    "\n",
    "        # Aplicar transformaciones\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.label_transform:\n",
    "            label = self.label_transform(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = CustomDataset(train_images, train_labels, transform, label_transform)\n",
    "val_dataset = CustomDataset(val_images, val_labels, transform, label_transform)\n",
    "test_dataset = CustomDataset(test_images, test_labels, transform, label_transform)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "\n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "\n",
    "        self.up4 = self.upconv(1024, 512)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        self.up3 = self.upconv(512, 256)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        self.up2 = self.upconv(256, 128)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        self.up1 = self.upconv(128, 64)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "\n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def upconv(self, in_channels, out_channels):\n",
    "        return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))\n",
    "        enc4 = self.enc4(F.max_pool2d(enc3, 2))\n",
    "\n",
    "        bottleneck = self.bottleneck(F.max_pool2d(enc4, 2))\n",
    "\n",
    "        dec4 = self.up4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.dec4(dec4)\n",
    "        dec3 = self.up3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.dec3(dec3)\n",
    "        dec2 = self.up2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.dec2(dec2)\n",
    "        dec1 = self.up1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.dec1(dec1)\n",
    "\n",
    "        return self.final(dec1)\n",
    "\n",
    "# Instanciar el modelo\n",
    "model = UNet()"
   ],
   "id": "896c121605de5fcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calcular el peso de la clase positiva\n",
    "num_positivos = sum(np.sum(label > 0) for label in labels)\n",
    "num_negativos = sum(np.sum(label == 0) for label in labels)\n",
    "pos_weight = torch.tensor([num_negativos / num_positivos]).to(DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # Cambiar a BCEWithLogitsLoss para trabajar con autocast\n",
    "optimizer = optim.Adam\n",
    "learning_rate = 1e-5\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Calcular pesos\n",
    "class_counts = [num_negativos, num_positivos]\n",
    "class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
    "sample_weights = [class_weights[0] if label.sum() == 0 else class_weights[1] for label in train_labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "batch_size = 4\n",
    "# Crear DataLoader con el sampler\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=0.00005)\n",
    "history = train_model(model, \n",
    "                      train_dataloader=train_loader,\n",
    "                      val_dataloader=val_loader,\n",
    "                      criterion = criterion,\n",
    "                      lr = learning_rate,\n",
    "                      optimizer = optimizer,\n",
    "                      epochs=25,\n",
    "                      early_stopper=early_stopper)"
   ],
   "id": "68b6a1ecf1d5d570"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_history(history, plot_list=[\"loss\", \"val_loss\"])",
   "id": "e79c85f44e117787"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def find_optimal_threshold(model, val_dataloader, thresholds=np.linspace(0.01, 0.9, 50)):\n",
    "    \"\"\"\n",
    "    Encuentra el umbral óptimo basado en el coeficiente de Dice.\n",
    "    \"\"\"\n",
    "    best_threshold = 0.5\n",
    "    best_dice = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for threshold in thresholds:\n",
    "            dice_scores = []\n",
    "            for vinputs, vtargets in val_dataloader:\n",
    "                vinputs, vtargets = vinputs.to(DEVICE), vtargets.to(DEVICE)\n",
    "                voutputs = torch.sigmoid(model(vinputs))\n",
    "                dice = calculate_dice(vtargets, voutputs, threshold)\n",
    "                dice_scores.append(dice)\n",
    "\n",
    "            avg_dice = sum(dice_scores) / len(dice_scores)\n",
    "            if avg_dice > best_dice:\n",
    "                best_dice = avg_dice\n",
    "                best_threshold = threshold\n",
    "\n",
    "    print(f\"Optimal threshold: {best_threshold} with Dice: {best_dice:.4f}\")\n",
    "    return best_threshold\n",
    "optimal_threshold = find_optimal_threshold(model, val_loader)"
   ],
   "id": "21b2825d2b8f9c29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_predictions(model, data_loader, num_samples=3, threshold=0.01):\n",
    "    \"\"\"\n",
    "    Visualiza las imágenes, etiquetas reales y predicciones del modelo.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): Modelo entrenado.\n",
    "        data_loader (DataLoader): DataLoader con las imágenes y etiquetas.\n",
    "        num_samples (int): Número de muestras a visualizar.\n",
    "        threshold (float): Umbral para binarizar las predicciones.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "\n",
    "    for i, (image, label) in enumerate(data_loader):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = torch.sigmoid(model(image.to(DEVICE))).cpu()  # Aplicar Sigmoid\n",
    "            pred = (pred > threshold).float()  # Binarizar las predicciones\n",
    "\n",
    "        # Convertir tensores a arrays NumPy\n",
    "        image_np = image[0].squeeze().cpu().numpy()\n",
    "        label_np = label[0].squeeze().cpu().numpy()\n",
    "        pred_np = pred[0].squeeze().cpu().numpy()\n",
    "\n",
    "        # Mostrar imágenes, etiquetas y predicciones\n",
    "        axes[i, 0].imshow(image_np, cmap='gray')\n",
    "        axes[i, 0].set_title('Input Image')\n",
    "        axes[i, 1].imshow(label_np, cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "        axes[i, 2].imshow(pred_np, cmap='gray')\n",
    "        axes[i, 2].set_title('Prediction')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "visualize_predictions(model, val_loader, num_samples=10, threshold=0.77)"
   ],
   "id": "71e686b919c2f7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2deb89e6428dcd1d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
